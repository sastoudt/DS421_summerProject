
\documentclass[12pt]{amsart}
\usepackage{geometry} % see geometry.pdf on how to lay out the page. There's lots.
\geometry{a4paper} % or letter or a5paper or ... etc
% \geometry{landscape} % rotated page geometry
\usepackage{color}
% See the ``Article customise'' template for come common customisations

\title{DS421 Summer 2016 Project Summary}
\author{Sara Stoudt}
%\date{} % delete this line to display the current date

%%% BEGIN DOCUMENT
\begin{document}

\maketitle
%\tableofcontents

\section{Investigation of Chlorophyll}

\subsection{Goals and Approaches}
The overarching goal of this portion of the project is to understand what variables help explain the variation of chlorophyll over time and at each station. We want to understand if these relationships differ over time and/or over space. My approach was to first see which other variables that we have information on at the same times and places as chlorophyll are correlated with chlorophyll. I included these variables in what I refer to as the ``parsimonious" model. I then added to a "full" model additional variables that were identified by David as variables whose relationships with chlorophyll, in context, would be interesting to understand. I build models including these variables separately for each station. Then I experimented with truly spatial models by using the station ID as a factor in a model, so I could fit one model and be able to predict chlorophyll for each station at once. After this I went back to make more ``bare bones" models per station that only incorporate the date (to incorporate trends over time) and the day of year (to incorporate seasonal trends) as well as the interaction between the two, allowing these trends to change depending on the value of the other one in order to have more fair comparisons between the various models. I then moved towards models that incorporate a sense of ``flow" using chlorophyll values from neighboring stations and measures of true flow throughout the area. 

Throughout all of these models, I fitted the models in a nested way so that we could see how much each variable contributed to the overall fitted value. I created a Shiny application (a web application written in R) to be able to compare and contrast the fitted values from each model, the contributions of each variable to the fitted values in each model, the overall RMSE per station of each model plotted on a map, and the contribution of volumetric flow averaged yearly and averaged monthly for each station.

\subsection{Details About the Setup}
I chose to use a log link function in each Generalized Additive Model since the distribution of chlorophyll is highly skewed right. I was deciding between log transforming the response and fitting a linear model ($log(y)=X\beta)+\epsilon$) versus using a Generalized Linear Model using a log link function ($log(y+\epsilon)= X\beta$) The residuals versus fitted values plots all look reasonable for constant variance under the GAM approach, so it did not seem necessary to use the log transform which would affect the variance as well as the linearity. We also don't have to deal with the back-transform bias where the back transform of the mean of the response on a log scale is not equivalent to the mean of the response on the raw scale.

I also had to choose which stations to focus on. I decided to pick stations that had records throughout the widest range of dates (from 1975-2015). These stations 15 stations (out of 41) are: C10, C3, D10, D12, D19, D22, D26, D28A, D4, D41, D6, D7, D8, MD10, and P8. This narrowed down the number of stations to a reasonable number (since I was often fitting a model per station) while still representing a wide spatial range. For a few of these stations, there was sufficient missingness in some of the variables of interest that I just decided to remove that variable from that particular model for that station. For full spatial models, I only used variables that were available across all of the stations.


\subsection{Parsimonious Model}

The parsimonious model used variables that visually looked correlated with chlorophyll overall along with temporal components. The day of year was included to account for any seasonality and was fit with a cyclic spline so that the ends match up from year to year. The date was included to account for any trends over time. The non-time covariates that were looked correlated were pheo (pheophytin a), tn (total nitrogen), and do.per (dissolved oxygen per ?). Note that do.per was more highly correlated than do (dissolved oxygen), but I'm not sure what the ``per" means. If in context, the ``per" variable doesn't make sense, it can be replaced with ordinary dissolved oxygen. All but day of year were fit with thin plate regression splines. These splines have some optimality properties, are low rank (needing to fit many fewer coefficients), and isotropic (rotation of the covariate coordinate system will not change the smoothing). The same model form was fit for each station. The maximum basis dimensions per variable change per station to allow for extra flexibility if need be and subject to the constraints of the data at each station.  

\textcolor{red}{come back and put results/observations}


\subsection{Full Model}

The full model included everything in the parsimonious model and then added some extra variables that are interesting in context but did not look particularly predictive of chlorophyll in pairwise scatterplots. The additional variables that were added are: sio2 (silica), tp (total phosphorus), tss (total suspended solids), nh4 (ammonia), sal (salinity). Again, all of these were fit with thin plate regression splines, the same model form was fit for each station, and the maximum basis dimensions per variable change per station.  Salinity, ammonia, and total nitrogen are the variables that have the most missingness and therefore don't occur in every station's model.

\textcolor{red}{come back and put results/observations}



\subsection{Spatial Models}

The above models were fit per station which did not allow for a true spatio-temporal analysis since each station could not leverage information from the other stations. I tried a few different set-ups for the spatial models in increasing level of complexity.

\begin{enumerate}
\item Spatial Model 1: Day of year and date with station as a factor. Same day of year and date trend, station just acts as an adjustment on the intercept.
\item Spatial Model 2: Day of year and date with station as a factor. Date is allowed to differ by station.
\item Spatial Model 3: Day of year and date with station as a factor. Date and day of year are both allowed to differ by station.
\item Spatial Model 4:  Day of year and date with station as a factor. Date is allowed to differ by station. The interaction between date and day of year is allowed to differ by station. Note that I didn't let day of year to differ by station here to scale back the complexity.
\end{enumerate}

\textcolor{red}{come back and put results/observations}

Now that we are incorporating more data and having many smooths being able to vary across each of 15 stations we have increasing complexity that carries over into the computational costs of fitting these models. 

\subsubsection{Computational Considerations}

I experimented with a few different solutions to the computational problems that came with fitting the spatial models. This really comes down to patience when working on a personal computer; nothing here is extremely computationally intensive, but for my work flow I wanted to have reasonable wait times of a few minutes per model. 

I refreshed my memory on how to take advantage of the Statistical Computing Facility's clusters and figured out how to move files back and forth and submit and monitor progress of various jobs. This is a good solution for fitting models that you are pretty sure of the size of the basis dimensions, but you don't want to wait around for the model to fit. For example, when I wanted to expand Spatial Model 3's basis dimensions to make sure I was making a fair comparison to another model later on in my process, I put it up on the cluster, and came back to get the results after a few hours.

However, in the trial and error phase of choosing basis dimensions, it is still kind of a pain to keep moving files back and forth to check diagnostic plots of various models. For this, I used mainly the ``bam" function in the mgcv package. This is a multiple thread version of the ``gam" function. There was a huge improvement in speed with only using 4 of the maximum 8 threads on my laptop.

I also recently learned how to switch my linear algebra package in R to be the vecLib version of BLAS which can give up to a linear time improvement. 

Once I learned to take advantage of all of these options, the computational complexity of the spatial model fitting was not a major obstacle to progress.


\section{Generalized Additive Model (GAM) and Weighted Regression on Time, Discharge, and Season (WRTDS) Comparison}

\end{document}